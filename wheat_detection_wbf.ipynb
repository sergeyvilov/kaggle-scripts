{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wheat_detection_wbf.ipynb","provenance":[{"file_id":"1X2lrgaUSYbvsW8dO1Yfq8FrtUpkj_8iM","timestamp":1595698133954}],"collapsed_sections":[],"authorship_tag":"ABX9TyN+jXZ8KRKj0EzYTnMdhjX+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"33896454961740cb8e63c44622965c46":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ead04e5da2d64eee9d500a648c3260f4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2ccd978b436747b888f229dd2660bf1a","IPY_MODEL_527ad634da544c65a7c4b888884f1e63"]}},"ead04e5da2d64eee9d500a648c3260f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ccd978b436747b888f229dd2660bf1a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_792f0c6a56514d5ca83ae121b547cac6","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":167502836,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":167502836,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1c5a44f1acc6435491f78e4acdcb8ede"}},"527ad634da544c65a7c4b888884f1e63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1b265c9927bd4af78573e0a3a63b2e91","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 160M/160M [00:56&lt;00:00, 2.98MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7ebbf51b4ca4c79847c6f819dddffe5"}},"792f0c6a56514d5ca83ae121b547cac6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1c5a44f1acc6435491f78e4acdcb8ede":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b265c9927bd4af78573e0a3a63b2e91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a7ebbf51b4ca4c79847c6f819dddffe5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab715b5659f34c14be792007cd9ce260":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ea8c657fe64b4d17a160b321b3398012","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a5b9e221154a47c1b2b4fb6f839d5eed","IPY_MODEL_a539926dad694b0d8a4f4a80c3edc6bc"]}},"ea8c657fe64b4d17a160b321b3398012":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5b9e221154a47c1b2b4fb6f839d5eed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d1d513e8344c4cf683fa740f6673faf2","_dom_classes":[],"description":"Metric: 0.824: 100%","_model_name":"FloatProgressModel","bar_style":"","max":85,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":85,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1d94bcf6576e4a46904a818a17e13ebe"}},"a539926dad694b0d8a4f4a80c3edc6bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_be6f82b4bd5847f284b3ab139c271f11","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 85/85 [02:28&lt;00:00,  1.32s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ab4385607b0b4802bf6a7042601f9248"}},"d1d513e8344c4cf683fa740f6673faf2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1d94bcf6576e4a46904a818a17e13ebe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be6f82b4bd5847f284b3ab139c271f11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ab4385607b0b4802bf6a7042601f9248":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"CcZ7lc20poqJ","executionInfo":{"status":"ok","timestamp":1595674232231,"user_tz":-120,"elapsed":18369,"user":{"displayName":"Sergey Vilov","photoUrl":"","userId":"16545205334574304565"}},"outputId":"7b64fa9e-f736-4565-b81a-645577e8d2e5","colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lh1p273oqOGx","executionInfo":{"status":"ok","timestamp":1595674235686,"user_tz":-120,"elapsed":8374,"user":{"displayName":"Sergey Vilov","photoUrl":"","userId":"16545205334574304565"}},"outputId":"ec24dd5c-38a8-4a38-c306-b0d3dff8ca5d","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["%cd '/content/drive/My Drive/DL'\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/DL\n","wheat.csv  wheat_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XnQcC76yBfbg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TqhKbcb0b9PE"},"source":["# %env CUDA_LAUNCH_BLOCKING=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e22xXmztzMof"},"source":["# !pip install -U git+https://github.com/albu/albumentations --no-cache-dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QcQedcEWqPyk"},"source":["import pandas as pd\n","import numpy as np\n","import cv2\n","import os\n","import re\n","import math\n","import copy\n","\n","from PIL import Image\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensor\n","\n","import torch\n","import torchvision\n","\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data.sampler import SequentialSampler\n","\n","from matplotlib import pyplot as plt\n","\n","DIR_INPUT = 'wheat_detection'\n","DIR_TRAIN = f'{DIR_INPUT}/train'\n","DIR_TEST = f'{DIR_INPUT}/test'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2KA1humQqRFL","executionInfo":{"status":"ok","timestamp":1595674242339,"user_tz":-120,"elapsed":1929,"user":{"displayName":"Sergey Vilov","photoUrl":"","userId":"16545205334574304565"}},"outputId":"5d5dc15c-2093-42b3-c5d8-3e3698e7f343","colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["# train_df = pd.read_csv(f'{DIR_INPUT}/wheat_train.csv')\n","# valid_df = pd.read_csv(f'{DIR_INPUT}/wheat_test.csv')\n","\n","# size_reduce_factor = 0.1\n","\n","# image_ids = train_df['image_id'].unique()\n","# image_ids = image_ids[0:round(len(image_ids)*size_reduce_factor)]\n","# train_df = train_df[train_df['image_id'].isin(image_ids)]\n","\n","# image_ids = valid_df['image_id'].unique()\n","# image_ids = image_ids[0:round(len(image_ids)*0.5)]\n","# valid_df = valid_df[valid_df['image_id'].isin(image_ids)]\n","\n","# train_df.describe()\n","\n","validation_fold = 0\n","\n","input_df = pd.read_csv(f'{DIR_INPUT}/wheat_1024.csv')\n","valid_df = input_df[input_df['fold']==validation_fold]\n","train_df = input_df[input_df['fold']!=validation_fold]\n","\n","# size_reduce_factor = 0.05\n","\n","# image_ids = train_df['image_id'].unique()\n","# image_ids = image_ids[0:round(len(image_ids)*size_reduce_factor)]\n","# train_df = train_df[train_df['image_id'].isin(image_ids)]\n","\n","# image_ids = valid_df['image_id'].unique()\n","# image_ids = image_ids[0:round(len(image_ids)*0.5)]\n","# valid_df = valid_df[valid_df['image_id'].isin(image_ids)]\n","\n","train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_id</th>\n","      <th>x_min</th>\n","      <th>y_min</th>\n","      <th>x_max</th>\n","      <th>y_max</th>\n","      <th>class_name</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>b6ab77fd7.jpg</td>\n","      <td>834.0</td>\n","      <td>222.0</td>\n","      <td>890.0</td>\n","      <td>258.0</td>\n","      <td>head</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>b6ab77fd7.jpg</td>\n","      <td>226.0</td>\n","      <td>548.0</td>\n","      <td>356.0</td>\n","      <td>606.0</td>\n","      <td>head</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b6ab77fd7.jpg</td>\n","      <td>377.0</td>\n","      <td>504.0</td>\n","      <td>451.0</td>\n","      <td>664.0</td>\n","      <td>head</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>b6ab77fd7.jpg</td>\n","      <td>834.0</td>\n","      <td>95.0</td>\n","      <td>943.0</td>\n","      <td>202.0</td>\n","      <td>head</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>b6ab77fd7.jpg</td>\n","      <td>26.0</td>\n","      <td>144.0</td>\n","      <td>150.0</td>\n","      <td>261.0</td>\n","      <td>head</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        image_id  x_min  y_min  x_max  y_max class_name  fold\n","0  b6ab77fd7.jpg  834.0  222.0  890.0  258.0       head     3\n","1  b6ab77fd7.jpg  226.0  548.0  356.0  606.0       head     3\n","2  b6ab77fd7.jpg  377.0  504.0  451.0  664.0       head     3\n","3  b6ab77fd7.jpg  834.0   95.0  943.0  202.0       head     3\n","4  b6ab77fd7.jpg   26.0  144.0  150.0  261.0       head     3"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"Yt_DuICfigPy"},"source":["disp_examples = False\n","\n","if disp_examples:\n","\n","  image_id = train_df['image_id'].iloc[1000]\n","  records = train_df[train_df['image_id']==image_id]\n","  boxes = records[['x_min', 'y_min', 'x_max', 'y_max']].values\n","  # fig, ax = plt.subplots(15, 1, figsize=(160, 80))\n","  img = cv2.imread(f'{DIR_TRAIN}/{image_id}', cv2.IMREAD_COLOR)\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)#convert to rgb\n","\n","  # img2 = img.copy()\n","  # augment_hsv(img2, hgain=0.2, sgain=0, vgain=0)\n","\n","  # img = cv2.flip(img,1)\n","\n","\n","  for box in boxes:\n","    # box = boxes[idx_box:]\n","    # x_min = 1024-box[0]\n","    img = cv2.rectangle(img,\n","                  (int(box[0]), int(box[1])),\n","                  (int(box[2]), int(box[3])),\n","                  (255,0,0),  2)\n","  # ax[0].imshow(img)\n","  plt.figure(figsize=(8,8))\n","  plt.imshow(img.astype(np.int))\n","\n","  # plt.figure(figsize=(8,8))\n","  # plt.imshow(img2.astype(np.int))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jOLbcgQ3Ljry"},"source":["# bin_width = 10\n","# bins = np.arange(0,256,bin_width)\n","# # hue_dist = np.zeros((bins.shape[0]-1,))\n","# hue_dist = list()\n","# value_dist = list()\n","# sat_dist = list()\n","# N_image = 0\n","\n","# for image_id in train_df['image_id'].unique():\n","  \n","#   img = cv2.imread(f'{DIR_TRAIN}/{image_id}', cv2.IMREAD_COLOR)\n","#   hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))\n","\n","#   # hst_hue,_ = np.histogram(hue,bins)\n","#   # hue_dist += hst_hue\n","#   # hue_dist.append(np.argmax(hst_hue))\n","\n","#   # hst_sat,_ = np.histogram(hue,bins)\n","#   # sat_dist.append(np.argmax(hst_sat))\n","\n","#   # hst_value,_ = np.histogram(hue,bins)\n","#   # value_dist.append(np.argmax(hst_value))\n","\n","#   hue_dist.append(np.median(hue.flatten()))\n","#   value_dist.append(np.median(sat.flatten()))\n","#   sat_dist.append(np.median(val.flatten()))\n","\n","#   N_image += 1\n","\n","#   if (N_image%100==0):\n","#     print(f\"{N_image} images processed\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0Ubu6rIMRqU"},"source":["# plt.bar(bins[:-1]+bin_width/2,hue_dist, width=10)\n","#plt.hist(hue_dist,bins)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w8pMo7RnqeXv"},"source":["from sklearn.utils import shuffle\n","import random\n","class WheatDataset(Dataset):\n","\n","    def __init__(self, dataframe, image_dir, transforms=None):\n","        super().__init__()\n","        \n","        self.df = dataframe\n","        self.image_ids = dataframe['image_id'].unique()\n","        # self.image_ids = shuffle(self.image_ids)\n","        self.labels = [np.zeros((0, 5), dtype=np.float32)] * len(self.image_ids)\n","        self.img_size = 1024\n","        im_w = 1024\n","        im_h = 1024\n","        for i, img_id in enumerate(self.image_ids):\n","            records = self.df[self.df['image_id'] == img_id]\n","            boxes = records[['x_min', 'y_min', 'x_max', 'y_max']].values\n","            # boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n","            # boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n","            boxesyolo = []\n","            for box in boxes:\n","                x1, y1, x2, y2 = box\n","                xc, yc, w, h = 0.5*x1/im_w+0.5*x2/im_w, 0.5*y1/im_h+0.5*y2/im_h, abs(x2/im_w-x1/im_w), abs(y2/im_h-y1/im_h)\n","                boxesyolo.append([0, xc, yc, w, h])\n","            self.labels[i] = np.array(boxesyolo)\n","        \n","        self.image_dir = image_dir\n","        self.transforms = transforms\n","        \n","        self.augment = True\n","        self.augment_colorspace = True\n","        self.minimum_boxes_to_augment = 10\n","\n","    def __getitem__(self, index: int):\n","\n","        image_id = self.image_ids[index]\n","        x = self.labels[index]\n","\n","        self.hflip = False\n","        self.vflip = False\n","        self.mosaic = False\n","\n","        if self.augment and len(x)>=self.minimum_boxes_to_augment:\n","\n","            if random.randint(0,1) == 0:\n","              self.hflip = True\n","\n","            if random.randint(0,1) == 0:\n","              self.vflip = True\n","\n","            if random.randint(0,1) == 0:\n","              self.mosaic = True\n","\n","        if self.mosaic:\n","                # Load mosaic\n","                img, labels = load_mosaic(self, index)\n","                shapes = None\n","\n","        else:\n","                # Load image\n","                img, (h0, w0), (h, w) = load_image(self, index)\n","\n","                # Letterbox\n","                shape = self.img_size  # final letterboxed shape\n","                img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)\n","                shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling\n","\n","                if x.size > 0:\n","\n","                    img, x = do_flips(self, img, x)\n","\n","                    # Normalized xywh to pixel xyxy format\n","                    labels = x.copy()\n","                    labels[:, 1] = ratio[0] * w * (x[:, 1] - x[:, 3] / 2) + pad[0]  # pad width\n","                    labels[:, 2] = ratio[1] * h * (x[:, 2] - x[:, 4] / 2) + pad[1]  # pad height\n","                    labels[:, 3] = ratio[0] * w * (x[:, 1] + x[:, 3] / 2) + pad[0]\n","                    labels[:, 4] = ratio[1] * h * (x[:, 2] + x[:, 4] / 2) + pad[1]\n","        \n","                if self.augment and len(x)>=self.minimum_boxes_to_augment:\n","                    # img, labels = random_affine(img, labels,\n","                    #                degrees= 15.,\n","                    #                translate=0.,\n","                    #                scale=0.2,\n","                    #                shear=0) \n","                    \n","                    img, labels = random_affine(img, labels, #version 2\n","                                   degrees= 0.,\n","                                   translate=0.,\n","                                   scale=0.,\n","                                   shear=0) \n","                    \n","                    \n","        if self.augment_colorspace:\n","            # Augment colorspace\n","            # augment_hsv(img, hgain=1, sgain=0.3, vgain=0.3)#full\n","            # augment_hsv(img, hgain=0.5, sgain=0.3, vgain=0.3)\n","            augment_hsv(img, hgain=0.0, sgain=0.1, vgain=0.1) #version 2\n","\n","        target = {}\n","\n","        class_labels = torch.ones((labels.shape[0],), dtype=torch.int64)\n","        \n","        target['boxes'] = labels[:,1:]\n","        target['labels'] = class_labels\n","        target['image_id'] = torch.tensor([index])\n","\n","\n","        if self.transforms:\n","            sample = {\n","                'image': img,\n","                'bboxes': target['boxes'],\n","                'labels': class_labels\n","            }\n","            sample = self.transforms(**sample)\n","            img = sample['image']\n","            \n","            target['boxes'] = torch.stack(tuple(map(lambda x:torch.tensor(x, dtype=torch.float32), zip(*sample['bboxes'])))).permute(1, 0)\n","\n","        return img, target, image_id\n","\n","\n","        # return img, labels\n","\n","    def __len__(self) -> int:\n","        return self.image_ids.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kpPxCp9ywdzb"},"source":["def load_image(self, index):\n","    # loads 1 image from dataset, returns img, original hw, resized hw\n","    image_id = self.image_ids[index]\n","    imgpath = f'{DIR_TRAIN}'\n","    img = cv2.imread(f'{imgpath}/{image_id}')\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)#convert to rgb\n","\n","    assert img is not None, 'Image Not Found ' + imgpath\n","    h0, w0 = img.shape[:2]  # orig hw\n","    return img, (h0, w0), img.shape[:2]  # img, hw_original, hw_resized"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZTidc3qgYcm"},"source":["def do_flips(self, img, labels_in):\n","\n","  labels = labels_in.copy()\n","  \n","  if self.hflip:\n","      img = cv2.flip(img, 1)\n","      labels[:, 1] = 1. - labels[:, 1]\n","  if self.vflip:\n","      img = cv2.flip(img, 0)\n","      labels[:, 2] = 1. - labels[:, 2]\n","\n","\n","  return img, labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j3lGaUo1wqmr"},"source":["def load_mosaic(self, index):\n","    # loads images in a mosaic\n","\n","    labels4 = []\n","    s = self.img_size\n","    xc, yc = [int(random.uniform(s * 0.5, s * 1.5)) for _ in range(2)]  # mosaic center x, y\n","    indices = [index] + [random.randint(0, len(self.labels) - 1) for _ in range(3)]  # 3 additional image indices\n","    for i, index in enumerate(indices):\n","        # Load image\n","        img, _, (h, w) = load_image(self, index)\n","\n","        x = self.labels[index]\n","\n","        img, x = do_flips(self, img, x)\n","\n","        labels = x.copy()\n","\n","        # place img in img4\n","        if i == 0:  # top left\n","            img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles\n","            x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)\n","            x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)\n","        elif i == 1:  # top right\n","            x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc\n","            x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h\n","        elif i == 2:  # bottom left\n","            x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)\n","            x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, max(xc, w), min(y2a - y1a, h)\n","        elif i == 3:  # bottom right\n","            x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)\n","            x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)\n","\n","        img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]\n","        padw = x1a - x1b\n","        padh = y1a - y1b\n","\n","\n","        if x.size > 0:  # Normalized xywh to pixel xyxy format\n","            labels[:, 1] = w * (x[:, 1] - x[:, 3] / 2) + padw\n","            labels[:, 2] = h * (x[:, 2] - x[:, 4] / 2) + padh\n","            labels[:, 3] = w * (x[:, 1] + x[:, 3] / 2) + padw\n","            labels[:, 4] = h * (x[:, 2] + x[:, 4] / 2) + padh\n","        labels4.append(labels)\n","\n","    # Concat/clip labels\n","    if len(labels4):\n","        labels4 = np.concatenate(labels4, 0)\n","        # np.clip(labels4[:, 1:] - s / 2, 0, s, out=labels4[:, 1:])  # use with center crop\n","        np.clip(labels4[:, 1:], 0, 2 * s, out=labels4[:, 1:])  # use with random_affine\n","\n","    # Augment\n","    # img4 = img4[s // 2: int(s * 1.5), s // 2:int(s * 1.5)]  # center crop (WARNING, requires box pruning)\n","    img4, labels4 = random_affine(img4, labels4,\n","                                   degrees=0.,\n","                                   translate=0.,\n","                                   scale=0.,\n","                                   shear=0,\n","                                   border=-s // 2)  # border to remove\n","    \n","    return img4, labels4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t6gEyUc9wtHd"},"source":["def random_affine(img, targets=(), degrees=10, translate=.1, scale=.1, shear=10, border=0):\n","    # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10))\n","    # https://medium.com/uruvideo/dataset-augmentation-with-random-homographies-a8f4b44830d4\n","\n","    if targets is None:  # targets = [cls, xyxy]\n","        targets = []\n","    height = img.shape[0] + border * 2\n","    width = img.shape[1] + border * 2\n","\n","    # Rotation and Scale\n","    R = np.eye(3)\n","    a = random.uniform(-degrees, degrees)\n","    a += random.choice([-180, -90, 0, 90])  # add 90deg rotations to small rotations\n","    s = random.uniform(1 - scale, 1 + scale)\n","    R[:2] = cv2.getRotationMatrix2D(angle=a, center=(img.shape[1] / 2, img.shape[0] / 2), scale=s)\n","\n","    # Translation\n","    T = np.eye(3)\n","    T[0, 2] = random.uniform(-translate, translate) * img.shape[0] + border  # x translation (pixels)\n","    T[1, 2] = random.uniform(-translate, translate) * img.shape[1] + border  # y translation (pixels)\n","\n","    # Shear\n","    S = np.eye(3)\n","    S[0, 1] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # x shear (deg)\n","    S[1, 0] = math.tan(random.uniform(-shear, shear) * math.pi / 180)  # y shear (deg)\n","\n","    # Combined rotation matrix\n","    M = S @ T @ R  # ORDER IS IMPORTANT HERE!!\n","    if (border != 0) or (M != np.eye(3)).any():  # image changed\n","        img = cv2.warpAffine(img, M[:2], dsize=(width, height), flags=cv2.INTER_LINEAR, borderValue=(np.random.randint(0,255), np.random.randint(0,255), np.random.randint(0,255)))\n","    \n","\n","    # Transform label coordinates\n","    n = len(targets)\n","    if n:\n","        # warp points\n","        xy = np.ones((n * 4, 3))\n","        xy[:, :2] = targets[:, [1, 2, 3, 4, 1, 4, 3, 2]].reshape(n * 4, 2)  # x1y1, x2y2, x1y2, x2y1\n","        xy = (xy @ M.T)[:, :2].reshape(n, 8)\n","\n","        # create new boxes\n","        x = xy[:, [0, 2, 4, 6]]\n","        y = xy[:, [1, 3, 5, 7]]\n","        xy = np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1))).reshape(4, n).T\n","\n","        # # apply angle-based reduction of bounding boxes\n","        # radians = a * math.pi / 180\n","        # reduction = max(abs(math.sin(radians)), abs(math.cos(radians))) ** 0.5\n","        # x = (xy[:, 2] + xy[:, 0]) / 2\n","        # y = (xy[:, 3] + xy[:, 1]) / 2\n","        # w = (xy[:, 2] - xy[:, 0]) * reduction\n","        # h = (xy[:, 3] - xy[:, 1]) * reduction\n","        # xy = np.concatenate((x - w / 2, y - h / 2, x + w / 2, y + h / 2)).reshape(4, n).T\n","\n","        # reject warped points outside of image\n","        xy[:, [0, 2]] = xy[:, [0, 2]].clip(0, width)\n","        xy[:, [1, 3]] = xy[:, [1, 3]].clip(0, height)\n","        w = xy[:, 2] - xy[:, 0]\n","        h = xy[:, 3] - xy[:, 1]\n","        area = w * h\n","        area0 = (targets[:, 3] - targets[:, 1]) * (targets[:, 4] - targets[:, 2])\n","        ar = np.maximum(w / (h + 1e-16), h / (w + 1e-16))  # aspect ratio\n","        i = (w > 4) & (h > 4) & (area / (area0 * s + 1e-16) > 0.2) & (ar < 10)\n","\n","        targets = targets[i]\n","        targets[:, 1:5] = xy[i]\n","\n","    return img, targets\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o6WXWxFzwvyc"},"source":["def augment_hsv(img, hgain=0.5, sgain=0.5, vgain=0.5):\n","    r = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # random gains +-hgain, +-sgain, +-vgain\n","    hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_RGB2HSV))\n","    dtype = img.dtype  # uint8\n","\n","    x = np.arange(0, 256, dtype=np.int16)\n","    lut_hue = ((x * r[0]) % 180).astype(dtype) #opencv codes hue btw 0 and 179 deg\n","    lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)\n","    lut_val = np.clip(x * r[2], 0, 255).astype(dtype)\n","\n","    img_hsv = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val))).astype(dtype)\n","    cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB, dst=img)  # no return needed #back to rgb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IiXvhXlzw0Gx"},"source":["def letterbox(img, new_shape=(416, 416), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True):\n","    # Resize image to a 32-pixel-multiple rectangle https://github.com/ultralytics/yolov3/issues/232\n","    shape = img.shape[:2]  # current shape [height, width]\n","    if isinstance(new_shape, int):\n","        new_shape = (new_shape, new_shape)\n","\n","    # Scale ratio (new / old)\n","    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n","    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n","        r = min(r, 1.0)\n","\n","    # Compute padding\n","    ratio = r, r  # width, height ratios\n","    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n","    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n","    if auto:  # minimum rectangle\n","        dw, dh = np.mod(dw, 64), np.mod(dh, 64)  # wh padding\n","    elif scaleFill:  # stretch\n","        dw, dh = 0.0, 0.0\n","        new_unpad = new_shape\n","        ratio = new_shape[0] / shape[1], new_shape[1] / shape[0]  # width, height ratios\n","\n","    dw /= 2  # divide padding into 2 sides\n","    dh /= 2\n","\n","    if shape[::-1] != new_unpad:  # resize\n","        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n","    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n","    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n","    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n","    return img, ratio, (dw, dh)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zr4WhrG_sFcK"},"source":["def get_train_transform():\n","    return A.Compose([\n","        # A.Flip(0.5),\n","        ToTensor()\n","    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n","\n","def get_valid_transform():\n","    return A.Compose([\n","        ToTensor()\n","    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFN9HEsQsXEA"},"source":["def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","train_dataset = WheatDataset(train_df, DIR_TRAIN, get_train_transform())\n","valid_dataset = WheatDataset(valid_df, DIR_TRAIN, get_valid_transform())\n","\n","valid_dataset.augment = False\n","valid_dataset.augment_colorspace = False\n","\n","train_data_loader = DataLoader(\n","    train_dataset,\n","    batch_size=16,\n","    shuffle=False,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")\n","\n","valid_data_loader = DataLoader(\n","    valid_dataset,\n","    batch_size=8,\n","    shuffle=False,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dCdFkDd3bGOr"},"source":["# torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iDyV9O8qe-_O"},"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Baka_5_Ysb7-"},"source":["train_dataset.augment = True\n","train_dataset.augment_colorspace = True\n","\n","disp_examples = False\n","\n","if disp_examples:\n","  images, targets, image_ids = next(iter(train_data_loader))\n","  # images, targets, image_ids = next(iter(valid_data_loader))\n","  images = list(image.to(device) for image in images)\n","  targets = [{k: v.to(device) for k, v in t.items()} for t in targets]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0dQemvwsfXE"},"source":["if disp_examples:\n","  \n","  imindex = random.randint(0,len(images)-1)\n","\n","  boxes = targets[imindex]['boxes'].cpu().numpy().astype(np.int32)\n","  sample = images[imindex].permute(1,2,0).cpu().numpy().astype(np.float32)\n","\n","  # imindex = random.randint(0,len(train_dataset)-1)\n","\n","  # boxes = train_dataset[imindex][1]['boxes'].numpy().astype(np.int32)\n","  # sample = train_dataset[imindex][0].permute(1,2,0).numpy().astype(np.float32)\n","\n","  fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","\n","  for box in boxes:\n","    cv2.rectangle(sample,\n","                  (box[0], box[1]),\n","                  (box[2], box[3]),\n","                  (1, 0, 0), 3)\n","    \n","  ax.set_axis_off()\n","  ax.imshow(sample)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ozuoBWx4k3ry"},"source":["def union(au, bu, area_intersection):\n","\tarea_a = (au[2] - au[0]) * (au[3] - au[1])\n","\tarea_b = (bu[2] - bu[0]) * (bu[3] - bu[1])\n","\tarea_union = area_a + area_b - area_intersection\n","\treturn area_union\n","\n","\n","def intersection(ai, bi):\n","\tx = max(ai[0], bi[0])\n","\ty = max(ai[1], bi[1])\n","\tw = min(ai[2], bi[2]) - x\n","\th = min(ai[3], bi[3]) - y\n","\tif w < 0 or h < 0:\n","\t\treturn 0\n","\treturn w*h\n","\n","\n","def iou(a, b):\n","\t# a and b should be (x1,y1,x2,y2)\n","\n","\tif a[0] >= a[2] or a[1] >= a[3] or b[0] >= b[2] or b[1] >= b[3]:\n","\t\treturn 0.0\n","\n","\tarea_i = intersection(a, b)\n","\tarea_u = union(a, b, area_i)\n","\n","\treturn float(area_i) / float(area_u + 1e-6)\n"," \n","def get_metric_image(gt_boxes, pred_boxes, conf, iou_thr):\n","\n","  N_pred_boxes = len(pred_boxes)\n","  N_gt_boxes = len(gt_boxes)\n","  M = np.zeros((N_pred_boxes, N_gt_boxes), dtype = bool)\n","\n","  pred_boxes = list(zip(pred_boxes, conf))\n","  sorted(pred_boxes, key=lambda x:x[1])\n","\n","  for idx_gt_box in range(N_gt_boxes):\n","    better_pred_box_found = 0\n","    for idx_pred_box in range(N_pred_boxes):\n","      res = (iou(pred_boxes[idx_pred_box][0], gt_boxes[idx_gt_box])>iou_thr)\n","      M[idx_pred_box, idx_gt_box] = (res &   ~better_pred_box_found)\n","      if res:\n","        better_pred_box_found = 1\n","\n","  FN = sum(M.sum(0)==0) #ground truth object had no associated predicted object.\n","  FP = sum(M.sum(1)==0) #predicted object had no associated ground truth object\n","  TP = N_pred_boxes-FP\n","\n","  # print('TP:{} FP:{} FN:{}\\n'.format(TP,FP,FN))\n","  return TP,FP,FN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pvoNSKgBKvGA"},"source":["%matplotlib inline\n","import time\n","import pylab as pl\n","from IPython import display\n","\n","\n","def disp_progress(hist, epoch):\n","\n","     display.clear_output(wait=True)\n","\n","     if isinstance(hist['train_loss'][0],float):\n","       train_loss = hist['train_loss']\n","     else:\n","       train_loss = list(zip(*hist['train_loss']))[-1]\n","\n","     val_metric = list(zip(*hist['val_metric']))[0]\n","     train_metric = list(zip(*hist['train_metric']))[0]\n","\n","     plt.figure(1)\n","     plt.clf()\n","     plt.plot(train_metric, 'r-', lw=2, label='train', Marker = '.', MarkerSize = 20)\n","     plt.plot(val_metric, 'b-', lw=2, label='val', Marker = '.', MarkerSize = 20)\n","     plt.legend()\n","     plt.grid()\n","     plt.ylabel('Metrics', fontsize=15)\n","     plt.xlabel('epoch', fontsize=15)\n","     display.display(plt.gcf())\n","     plt.close()\n","\n","     plt.figure(2)\n","     plt.clf()\n","     plt.plot(train_loss, 'r-', lw=1, Marker = '.', MarkerSize = 20)\n","     plt.grid()\n","     plt.ylabel('Training loss', fontsize=15)\n","     plt.xlabel('epoch', fontsize=15)\n","     display.display(plt.gcf())\n","     plt.close()\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_dp_uWtuupMz"},"source":["from tqdm.notebook import tqdm\n","import time\n","\n","def train(model):\n","\n","  beta = 0.98\n","\n","  train_itr = 1\n","\n","  model.train()\n","\n","  # loss_hist = list()\n","\n","  # N_images = 0\n","  \n","  avg_loss = 0.\n","\n","  pbar = tqdm(total = math.ceil(len(train_dataset)/train_data_loader.batch_size))\n","\n","  for images, targets, _ in train_data_loader:\n","       \n","\n","      images = list(image.to(device)for image in images)\n","      targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","      #Triangular sheduler \n","      if isinstance(lr_scheduler, TriangularSchedule):\n","\n","          optimizer.param_groups[0]['lr'] = lr_scheduler.lr\n","          optimizer.param_groups[0]['momentum'] = lr_scheduler.momentum\n","\n","      loss_dict = model(images, targets)\n","\n","      losses = sum(loss for loss in loss_dict.values())\n","\n","      # loss_hist.append([x.item() for y,x in loss_dict.items()])\n","      \n","      # N_images += len(images)\n","    \n","      # train_loss = np.sum(list(zip(*loss_hist)),1)/(N_images)\n","      # train_loss = np.append(train_loss, np.sum(train_loss))\n","\n","      train_itr += 1\n","\n","      avg_loss = beta * avg_loss + (1-beta)*losses.item()/len(images)\n","      smoothed_loss = avg_loss / (1 - beta**train_itr) \n","        \n","      # if train_itr % 10 == 0:\n","      #     print(f\"Iteration #{train_itr} loss: {train_loss[-1]}\")\n","\n","      pbar.update(1)\n","      pbar.set_description(f\"Running loss:{smoothed_loss:.8f}\")\n","\n","      # del images\n","      # if train_itr < 5:\n","      #     time.sleep(10)\n","\n","      optimizer.zero_grad()\n","      losses.backward()\n","      optimizer.step()\n","\n","      if isinstance(lr_scheduler, TriangularSchedule):\n","        lr_scheduler.step()\n","\n","  del pbar\n","\n","  return smoothed_loss\n","\n","def validate(model, data_loader, max_itr, iou_thr=0.5, detection_thr = 0.):\n","\n","  model.eval()\n","\n","  val_metric = 0.\n","  FP_tot = 0.\n","  TP_tot = 0.\n","  FN_tot = 0.\n","\n","  val_itr = 0\n","\n","  N_images = 0\n","\n","  pbar = tqdm(total = max_itr)\n","\n","  with torch.no_grad():\n","\n","    for images, targets, _ in data_loader:\n","\n","      images = list(image.to(device) for image in images)\n","\n","      outputs = model(images)\n","\n","      for idx_image in range(len(images)):\n","\n","          pred_boxes =  outputs[idx_image]['boxes'].cpu().numpy()\n","          conf = outputs[idx_image]['scores'].cpu().numpy()\n","\n","          gt_boxes = targets[idx_image]['boxes'].numpy()\n","\n","          pred_boxes = pred_boxes[conf >= detection_thr]\n","          conf = conf[conf >= detection_thr]\n","\n","          TP,FP,FN = get_metric_image(gt_boxes, pred_boxes, conf, iou_thr)\n","\n","          TP_tot += TP\n","          FP_tot += FP\n","          FN_tot += FN\n","\n","          val_metric += TP/float(TP+FP+FN)\n","\n","      val_itr += 1\n","\n","      N_images += len(images)\n","\n","      pbar.update(1)\n","      pbar.set_description(f\"Metric: {val_metric/N_images:.3f}\")\n","\n","      if val_itr == max_itr:\n","        break\n","\n","  del pbar\n","\n","  return val_metric/N_images, TP_tot/N_images, FP_tot/N_images, FN_tot/N_images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nBiw9natsPO4","executionInfo":{"status":"ok","timestamp":1595674294014,"user_tz":-120,"elapsed":13550,"user":{"displayName":"Sergey Vilov","photoUrl":"","userId":"16545205334574304565"}},"outputId":"36be8e2c-8daa-4751-acc1-3884b520a880","colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["33896454961740cb8e63c44622965c46","ead04e5da2d64eee9d500a648c3260f4","2ccd978b436747b888f229dd2660bf1a","527ad634da544c65a7c4b888884f1e63","792f0c6a56514d5ca83ae121b547cac6","1c5a44f1acc6435491f78e4acdcb8ede","1b265c9927bd4af78573e0a3a63b2e91","a7ebbf51b4ca4c79847c6f819dddffe5"]}},"source":["# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, rpn_nms_thresh = 0.83)\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, rpn_nms_thresh = 0.83)\n","\n","# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","\n","num_classes = 2  # 1 class (wheat) + background\n","\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","model.to(device)\n","params = [p for p in model.parameters() if p.requires_grad]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33896454961740cb8e63c44622965c46","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=167502836.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i308vBl7LYaW"},"source":["def find_lr(init_value = 1e-8, final_value = 10., weight_decay = 0.0, num = None, beta = 0.9):\n","\n","    if num == None:\n","      num = len(train_dataset)//float(train_data_loader.batch_size)\n","\n","    mult = (final_value / init_value) ** (1/num)\n","    lr = init_value\n","\n","    optimizer.param_groups[0]['lr'] = lr\n","    optimizer.param_groups[0]['weight_decay'] = weight_decay\n","\n","    # optimizer = torch.optim.Adam(params, lr=lr)\n","    avg_loss = 0.\n","    best_loss = 0.\n","    batch_num = 0\n","    losses = []\n","    log_lrs = []\n","\n","    pbar = tqdm(total = num)\n","\n","    model.train()\n","\n","    for data in train_data_loader:\n","\n","        batch_num += 1\n","\n","        #As before, get the loss for this mini-batch of inputs/outputs\n","        images,targets,_ = data\n","        images = list(image.to(device)for image in images)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","        loss_dict = model(images, targets)\n","        loss = sum(loss for loss in loss_dict.values())\n","\n","        #Compute the smoothed loss\n","        avg_loss = beta * avg_loss + (1-beta) *loss.item()\n","        smoothed_loss = avg_loss / (1 - beta**batch_num)\n","\n","        #Stop if the loss is exploding\n","        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n","            return log_lrs, losses\n","\n","        #Record the best loss\n","        if smoothed_loss < best_loss or batch_num==1:\n","            best_loss = smoothed_loss\n","\n","        #Store the values\n","        losses.append(smoothed_loss)\n","        log_lrs.append(math.log10(lr))\n","\n","        #Do the SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        pbar.update(1)\n","        pbar.set_description(f\"LR: {lr:e} Loss: {smoothed_loss:.5f}\")\n","\n","        #Update the lr for the next step\n","        lr *= mult\n","        optimizer.param_groups[0]['lr'] = lr\n","        # optimizer = torch.optim.Adam(params, lr=lr)\n","\n","        if batch_num>=num:\n","          break\n","\n","    del pbar \n","\n","    return log_lrs, losses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UaLZozStNezn"},"source":["#get LR plot for several weight decays\n","# log_lrs = []\n","# losses = []\n","# optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9)#, weight_decay=0.0005)\n","\n","# total_iter = len(train_dataset)//float(train_data_loader.batch_size)//2\n","\n","# for wd in [0, 1e-5, 1e-4, 1e-3]:\n","#   print(f'Computing learning rates for weight decay:{wd:g}')\n","#   model.load_state_dict(torch.load('/content/drive/My Drive/DL/wheat_detection/models/NMS_04_state0'))\n","#   log_lrs_, losses_ = find_lr(1e-8, 10, wd, total_iter)\n","#   log_lrs.append(log_lrs_)\n","#   losses.append(losses_)\n","\n","\n","\n","# plt.plot(log_lrs[0], losses[0], 'r--', log_lrs[1], losses[1], 'b.-', log_lrs[2], losses[2], 'g^', log_lrs[3], losses[3], 'k')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qCsQcf1PWvgS"},"source":["class TriangularSchedule():\n","\n","      def __init__(self, epochs_per_cycle, batches_per_epoch,  min_LR, max_LR, iter = 0, min_momentum = 0.8, max_momentum = 0.95):\n","\n","        self.cycle_length = batches_per_epoch*epochs_per_cycle\n","\n","        self.min_LR = min_LR\n","        self.max_LR = max_LR\n","        self.min_momentum = min_momentum\n","        self.max_momentum = max_momentum\n","        self.lr_slope = (max_LR - min_LR)/(self.cycle_length//2)\n","        self.momentum_slope = (max_momentum - min_momentum)/(self.cycle_length//2)\n","\n","        self.iter = iter\n","        self.step()\n","\n","      def step(self):\n","\n","        if self.iter <= self.cycle_length//2:\n","\n","          self.lr = self.min_LR + self.iter * self.lr_slope #increase lr\n","          self.momentum = self.max_momentum - self.iter * self.momentum_slope #reduce momentum\n","\n","        else:\n","\n","          self.lr = self.max_LR - (self.iter - self.cycle_length//2) * self.lr_slope\n","          self.momentum = self.min_momentum + (self.iter - self.cycle_length//2) * self.momentum_slope\n","\n","        self.iter += 1\n","\n","        if self.iter >= self.cycle_length:\n","          self.iter = 0\n","\n","      def reset(self):\n","\n","        self.iter = 0\n","        self.step()\n","\n","      def get_all(self):\n","\n","        return {'lr':self.lr, 'momentum':self.momentum, 'iter':self.iter, 'min_lr':self.min_LR, 'max_lr':self.max_LR, 'min_momentum':self.min_momentum,\n","                'max_momentum': self.max_momentum, 'cycle_length':self.cycle_length}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOXpbX11noiM"},"source":["optimizer = torch.optim.SGD(params, lr=0.005)#, weight_decay=0.0005)\n","lr_scheduler = TriangularSchedule(epochs_per_cycle = 8, batches_per_epoch = math.ceil(len(train_dataset)/train_data_loader.batch_size),  min_LR = 2e-3, max_LR = 8e-3)\n","\n","# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n","# optimizer = torch.optim.Adam(params, lr=2e-4)\n","# optimizer = torch.optim.Adam(params, lr=2e-4)\n","# optimizer = torch.optim.RMSprop(params, lr=1e-4)\n","# lr_scheduler = None\n","\n","# model.load_state_dict(torch.load('/content/drive/My Drive/DL/wheat_detection/models/NMS_04_state0'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XYWJ7CKf9dFT"},"source":["#check triangularscheduler\n","\n","# lrates = []\n","# momenta = []\n","# for i_iter in range(math.ceil(len(train_dataset)/train_data_loader.batch_size)*8):\n","#   lrates.append(lr_scheduler.lr)\n","#   momenta.append(lr_scheduler.momentum)\n","#   lr_scheduler.step()\n","\n","# print(f'LR scheduler parameters:\\n')\n","\n","# print(lr_scheduler.get_all())\n","\n","# lr_scheduler.reset()\n","\n","# print(f'LR scheduler parameters after reset:\\n')\n","\n","# print(lr_scheduler.get_all())\n","\n","# # plt.plot(lrates)\n","# plt.plot(momenta)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXii585lnM6_"},"source":["load_weights = True\n","if load_weights:\n","  import pickle\n","  model_file_base = '/content/drive/My Drive/DL/wheat_detection/models/SGD_NMS096_AUGM2x_1024_FOLD_0/24_07_epoch_38'\n","  model_file_base = '/content/drive/My Drive/DL/wheat_detection/models/SGD_NMS083_AUGM2x_1024_FOLD_0/25_07_epoch_8'\n","\n","  model.load_state_dict(torch.load(model_file_base + '_weights'))\n","  # optimizer.load_state_dict(torch.load(model_file_base + '_optimizer'))\n","  model_meta = pickle.load(open(model_file_base+ '_hist','rb'))\n","  first_epoch = model_meta['epoch']+1\n","  hist = model_meta['hist']\n","  best_val_metric = hist['val_metric'][-1][0]\n","  if not 'lr_scheduler' in model_meta.keys():\n","    itr = first_epoch%8*math.ceil(len(train_dataset)/train_data_loader.batch_size)-1\n","    lr_scheduler = TriangularSchedule(epochs_per_cycle = 8, batches_per_epoch = math.ceil(len(train_dataset)/train_data_loader.batch_size),  min_LR = 2e-3, max_LR = 8e-3, iter=itr)\n","  else:\n","    lr_scheduler = model_meta['lr_scheduler']  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYh8zBdQICod","executionInfo":{"status":"ok","timestamp":1595623078048,"user_tz":-120,"elapsed":1582,"user":{"displayName":"Sergey Vilov","photoUrl":"","userId":"16545205334574304565"}},"outputId":"56c88c44-8303-4884-bf08-7a80d4998c4b","colab":{"base_uri":"https://localhost:8080/","height":568}},"source":["# import pickle\n","# # model_file_base = '/content/drive/My Drive/DL/wheat_detection/models/SGD_NMS096_AUGM_2x_FOLD_0/17_07_epoch_28'\n","# model_file_base = '/content/drive/My Drive/DL/wheat_detection/models/SGD_FOLD_0/10_07_epoch_28'\n","# model_file_base = '/content/drive/My Drive/DL/wheat_detection/models/SGD_NMS096_FOLD_0/22_07_epoch_20'\n","# model_file_base = '/content/drive/My Drive/DL/wheat_detection/models/SGD_NMS096_AUGM2x_1024_FOLD_0/24_07_epoch_38'\n","\n","\n","# model_meta = pickle.load(open(model_file_base+ '_hist','rb'))\n","# disp_progress(model_meta['hist'],0)\n","# model_meta['hist']['val_metric'][-1]"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZMAAAELCAYAAAAcKWtPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZyVdZ3/8deHmeFmHMZcwdkWVBRxW2rJHJJuFTALrJXK0dAgK41IadWwYjd/qOy2m61Gtbi5ihZqLSqWkoLmL8Csn6FihqBpM6SBupp4x8jdAJ/fH9/ryOFwbq4517mbmffz8bgec67r+p7r+pxTnI/fm+v7NXdHREQkiX7VDkBERHo+JRMREUlMyURERBJTMhERkcSUTEREJLH6agdQLUOGDPERI0YU9d433niDAw44oLQBlZDiS0bxJaP4kqn1+NasWfOSuw/d74S798mttbXVi7Vy5cqi31sJii8ZxZeM4kum1uMDHvYsv6lq5hIRkcSUTEREJDElExERSUzJJK6ODjj3XGhu5oSJE6G5Oex3dFQ7MhGRqlMyiWP5chgzBhYuhC1bMHfYsiXsjxkTzouI9GEVTyZmNsnMnjSzdjObk+X8ADO7OTq/2sxGpJ0bY2YPmNl6M3vMzAZGx1uj/XYz+76ZWckC7uiAtjbYuhW6uvY919UVjre1qYYiIn1aRZOJmdUBVwGTgdHAGWY2OqPY2cAr7n4UMB+4PHpvPXATMNPd3w6MB1K/7j8AvgCMirZJJQv6yiv3TyKZurpg/vyS3VJEpKepdM3kOKDd3Te4+05gMTAlo8wUYFH0eglwYlTT+DCw1t1/D+Dum919t5m9FWh2999GY6BvAD5esohvuileMrnxxpLdUkSkp6n0E/DDgI1p+5uAcbnKuPsuM3sNOBg4GnAzuwcYCix2929H5TdlXHNYtpub2QxgBkBLSwurVq0qGPAJnZ3EaTPzLVu4L8b1KqGzszPWZ6sWxZeM4ktG8ZVHT5pOpR74APBuYCvwSzNbA7wW9wLufg1wDcDYsWN9/Pjxhd/U1BQ62wuwwYOJdb0KWLVqVc3Eko3iS0bxJaP4yqPSzVzPAoem7Q+PjmUtE/WTHAhsJtQ4fuXuL7n7VmAZcGxUfniBaxZv2jRoaMhfpqEBpk8v2S1FRHqaSieTh4BRZnaEmfUHpgJLM8osBc6KXrcBK6K+kHuAvzezxijJnAA87u7PA6+b2XuivpXPAHeULOLZs+MlkwsvLNktRUR6moomE3ffBcwiJIYngFvcfb2ZzTOzU6Ji1wEHm1k78BVgTvTeV4DvEBLSo8Aj7n5X9J5zgYVAO9ABlO7Bj5EjYckSaGzcP6k0NITjS5aEciIifVTF+0zcfRmhiSr92Ny019uB03K89ybC8ODM4w8D7yhtpGkmT4a1a8Pw3xtvxF9/HRs8GD7zmVAjUSIRkT5OT8DHNXIkLFgAr73GtkMPhd/+NuwrkYiIKJkUY3tLCzzzTLXDEBGpGUomRdje0gJ//nO1wxARqRlKJkXYoZqJiMg+lEyKsP2QQ1QzERFJo2RSBPWZiIjsS8mkCDvUZyIisg8lkyLsGDoUnn8edu2qdigiIjVByaQIXl8PhxwCzz1X7VBERGqCkkmxDjtM/SYiIhElk2Idfrj6TUREIkomxVLNRETkTUomxVLNRETkTUomxTrsMCUTEZGIkkmxDj9czVwiIhElk2Klaibu1Y5ERKTqlEyKdeCBUFcHr7xS7UhERKpOySQJ9ZuIiABKJsmo30REBFAySUY1ExERoArJxMwmmdmTZtZuZnOynB9gZjdH51eb2Yjo+Agz22Zmj0bb1WnvOcPMHjOztWZ2t5kNqciHUc1ERASocDIxszrgKmAyMBo4w8xGZxQ7G3jF3Y8C5gOXp53rcPdjom1mdM164HvABHcfA6wFZpX5owSqmYiIAJWvmRwHtLv7BnffCSwGpmSUmQIsil4vAU40M8tzTYu2A6JyzUBlpvPVlCoiIgCYV/A5CTNrAya5+znR/nRgnLvPSiuzLiqzKdrvAMYBTcB64CngdeBid78/7brXA28AfyTUUnZnuf8MYAZAS0tL6+LFi4v6HJ2dnTQ1NdH/L3+hdeZMHrjttqKuUy6p+GqV4ktG8SWj+JKZMGHCGncfu98Jd6/YBrQBC9P2pwMLMsqsA4an7XcAQ4ABwMHRsVZgI6EW0gD8EhhJqKEsICSavLG0trZ6sVauXBle7Nrl3r+/+7ZtRV+rHN6Mr0YpvmQUXzKKLxngYc/ym1rpZq5ngUPT9odHx7KWifpDDgQ2u/sOd98M4O5rCEnmaOCY6FhH9EFvAd5Xzg/xpro6GDYMNm2qyO1ERGpVpZPJQ8AoMzvCzPoDU4GlGWWWAmdFr9uAFe7uZjY06sDHzI4ERgEbCMlntJkNjd5zEvBEmT/HXuo3ERGhvpI3c/ddZjYLuAeoA6539/VmNo9QdVoKXAfcaGbtwMuEhANwPDDPzLqAPcBMd38ZwMwuA34VnXsG+GzFPpSmohcRqWwyAXD3ZcCyjGNz015vB07L8r7bgKw93e5+NXB1tnNlp5qJiIiegE9MNRMRESWTxPTgooiIkklimlJFRETJJLFDD4WNG2HPnmpHIiJSNUomSTU2QnMzvPhitSMREakaJZNSUL+JiPRxSialoH4TEenjlExKQTUTEenjlExKQQ8uikgfp2RSCnpwUUT6OCWTUlDNRET6OCWTUlDNRET6OCWTUhgyBLZtg87OakciIlIVSialYKYRXSLSpymZlIr6TUSkD1MyKRX1m4hIH6ZkUiqqmYhIH6ZkUiqqmYhIH6ZkUiqqmYhIH5YomZjZW0oVSI+nmomI9GGxkomZfcnMvpa2f4yZbQI2m9kaMxse94ZmNsnMnjSzdjObk+X8ADO7OTq/2sxGRMdHmNk2M3s02q5Oe09/M7vGzJ4ysz+Y2alx4ymZYcPg+edh166K31pEpNri1ky+DLyetv994Dng09E1vhXnImZWB1wFTAZGA2eY2eiMYmcDr7j7UcB84PK0cx3ufky0zUw7/g3gRXc/OrrufTE/V+n07w+HHALPPVfxW4uIVFt9zHKHAU8CmNlQ4P3Aie6+ysx2AgtiXuc4oN3dN0TXWgxMAR5PKzMFuDR6vQRYYGZW4LqfB94G4O57gJdixlNaqQcXDzusKrcXEamWuMlkB9A/ej0B2ArcH+2/DMTtOxkGbEzb3wSMy1XG3XeZ2WvAwdG5I8zsd4Ra0sXufn9av82/mNl4oAOY5e4vZN7czGYAMwBaWlpYtWpVzLD31dnZmfW9owcO5KXly3mxyk1dueKrFYovGcWXjOIrE3cvuAHLgaXA24FfA7emnfs8obYR5zptwMK0/enAgowy64DhafsdwBBgAHBwdKyVkHCao3MOtEXnvgLcWCiW1tZWL9bKlSuzn/ja19z/7d+Kvm6p5IyvRii+ZBRfMoovGeBhz/KbGrfPZHaUSB4DDiX0UaR8CvhNzOs8G70/ZXh0LGsZM6sHDgQ2u/sOd98M4O5rCEnmaGAzoab00+j9twLHxoyntDQ8WET6qFjJxN0fd/eRwFBghLs/lXb6omiL4yFglJkdYWb9gamEGk+6pcBZ0es2YIW7u5kNjTrwMbMjgVHAhihT/hwYH73nRPbtg6kcDQ8WkT4qbp8JAKmaAYCZHQQcDjzh7jtivn+Xmc0C7gHqgOvdfb2ZzSNUnZYC1wE3mlk7oT9mavT244F5ZtYF7AFmuvvL0bmvR+/5LvAX4HPd+Vwlo5qJiPRRsZKJmV0GDHD3OdH+ROAOoBF43sw+4u7r41zL3ZcByzKOzU17vR04Lcv7bgNuy3HNZwjJpno6OuD734fHH4d+/aCpCaZNg9mzYeTIqoYmIlJucftMPg38IW3/SkJH/PuBp4B/L3FcPcvy5TBmDNxwQ9h3hy1bYOHCcHz58urGJyJSZnGTyd8AqWdDDgXeCVzi7r8lJJb3lCe8HqCjA9raYOtW6Ora91xXVzje1hbKiYj0UnGTyRbCqCqAiYQn1B+M9rcTmrv6piuv3D+JZOrqgvnzKxOPiEgVxE0m9wFzzOyjhJFbd6SdO5p9H0TsW266KV4yufHGysQjIlIFcZPJhYSn4BcDr7LvcyafAX5V4rh6js7O0pYTEemBYo3mcvdnCc1b2XyE0NTVNzU1hc72OOVERHqpbq1nEk313mpmJ0V/+7v76+6+s1wB1rxp06ChIX+ZhgaYPr0y8YiIVEHsZBKtZ/IC8CDhocMHgRfM7Ktliq1nmD07XjK58MLKxCMiUgVxF8e6gPAsyU8Iswb/XfT3J8C/m9k/li3CWjdyJCxZAo2N+yeV+vpwfMkSPbgoIr1a3JrJecC33P08d/+Vuz8Z/T2PsHhV300mAJMnw9q1MGMGNDeHJ+AbGuB97wvHJ0+udoQiImUVN5kcCqzMcW4VYfbfvm3kSFiwAF57DXbvhltvhbo61UhEpE+Im0z+DHw4x7mTovOS7sMfhkcegRdfrHYkIiJlFzeZfB+4yMwWmtkkM3uXmX3EzBYSFqP6XvlC7KEGDQrNW7ffXu1IRETKLu56JguALwKTCDP+PkxYfXESYSr4q8oWYU/W1hY630VEernYQ4Pd/VpC38nhwHujv4e6+8IyxdbzTZ4Mq1fD5s2Fy4qI9GDdemgxWgJ4o7s/GP31cgXWKzQ2hr6TO+4oXFZEpAfLOZ2KmZ3bjeu4u/+gBPH0Pm1t8KMfwec/X+1IRETKJt/cXAu6cR0HlEyy+ehHw/Mnr7wCBx1U7WhERMoiZzOXu/frxlZXyaB7lKYmOPFEWLq02pGIiJRNt/pMpEga1SUivVzFk0n0nMqTZtZuZnOynB9gZjdH51eb2Yjo+Agz22Zmj0bb1Vneu9TM1pX/U3TTxz4G990Xno4XEemFKppMzKwOuAqYDIwGzjCz0RnFziYsC3wUMJ8w91dKh7sfE20zM679SaA2V6Bqbobx4+HOO6sdiYhIWVS6ZnIc0O7uG6I1UBYDUzLKTAEWRa+XACeameW7qJk1EZ7E/9cSx1s6auoSkV7MKvmoiJm1AZPc/Zxofzowzt1npZVZF5XZFO13AOOAJmA98BTwOnCxu98flZlPWDr4d8Cd7v6OHPefAcwAaGlpaV28eHFRn6Ozs5Ombq6c2PTUUxx73nnsaWigbvt2dg8axAsf+hAbTz+d7cOGFRVHKeOrJMWXjOJLRvElM2HChDXuPna/E+5esQ1oAxam7U8HFmSUWQcMT9vvAIYAA4CDo2OtwEagGTgGWBodHwGsixNLa2urF2vlypXde8OyZe6Nje5m7rB3a2gIx5ctKzqWksRXYYovGcWXjOJLBnjYs/ymxloD3szm5jm9h1BT+L2731fgUs8SpmRJGR4dy1Zmk5nVAwcCm6MPsQPA3ddENZajgXcDY83sacJzM4eY2Sp3Hx/ns5VdR0do4tq6df9zXV1ha2sL655ounoR6aFiJRPgy8BA4IBov5PQ7ATwRnSdAWb2KDDZ3V/IcZ2HgFFmdgQhaUwFzswosxQ4C3iAUJNZ4e5uZkOBl919t5kdCYwCNrj7w0QPTEYjv+6smUQCcOWVIWHk09UF8+eH9VBERHqguB3wJwPPA58CBrl7MzCIkAyeBz4EHA8MBa7MdRF33wXMIqwh/wRwi7uvN7N5ZnZKVOw64GAzayd0qqeGDx8PrI0S1hLCbMUvx/6k1XLTTfGSyY03ViYeEZEyiFszWUBYtvfW1AF33wHcYmaDgf9092PN7F8pMKLK3ZcRprFPPzY37fV24LQs77sNuK3AtZ8Gsna+V01nzNHKccuJiNSguDWTMcD/5jj3PPB30es/AIOTBtWrxB2VUcOjN0RECombTJ4Czjez/ukHzWwAcCHwZHTor4Fc/SV907Rp0NCQv0xDA0yfXpl4RETKIG4z1/nAXYQRVvcCfyH0j5xE6JQ/OSr3LuCnpQ6yR5s9GxYtyt9v0tAAF15YuZhEREos7rK9qwijpxYBfwN8JPr7I2BUakiwu89xd/0qphs5Mjz53ti4fw2lX79wfMkSDQsWkR4tbs0Ed38O+GoZY+m9Jk8Oz5HMnx9GbXV2wgEHwM6dYQLIsfs/TCoi0pNoCvpKGTkyPEfy2muweze8/jqceSbcfXe1IxMRSSxWMjGzBjO7yMz+n5n92cxezNzKHWivNHt2SDDbt1c7EhGRROI2c80HvgjcCawEdpYtor7k7W+H1tbQ9PWFL1Q7GhGRosVNJqcBc9w959PtUqSvfhVmzoSzzw4d8iIiPVDcXy8D1pYzkD7rhBPCA4taOEtEerC4yeRa4IxyBtJnmYXayRVXVDsSEZGixW3megH4tJmtBO4FXs047+7+g5JG1peceirMmQOrV8O4cdWORkSk2+Imk+9Gfw8DTshy3ommgZci1NeH6VTOPBP+8pfwHEpTU5iKZfZsPdAoIjUv7hPw/QpsdeUOtFdbvjyse7JhA2zZEtZh3LIFFi6EMWPCeRGRGqbhQ9VWaCXGrVvD+Y6OyscmIhJTzmYuMxsNdLj7juh1Xu7+eEkj6yu0EqOI9AL5+kzWAe8BHoxee45yFp1TU1cxurMSo5KJiNSofMlkAvB42mspB63EKCK9QM5kkppWPvO1lFhTU+hsj1NORKRGdbsD3szqzKwxcytHcH2CVmIUkV4g7qzBzWa2wMyeA3YAW7JssZjZJDN70szazWxOlvMDzOzm6PxqMxsRHR9hZtvM7NFouzo63mhmd5nZH8xsvZl9K24sNWH27HjJRCsxikgNi/vQ4n8DHwMWEvpRipo12MzqgKsIy/1uAh4ys6UZI8HOBl5x96PMbCpwOfCp6FyHux+T5dJXuPvKaI36X5rZZHfvGQ9npFZibGsLHe3pnfF1dbBnD/zkJ3pwUURqWtxk8hHgQndfmPB+xwHt7r4BwMwWA1PY29FPtH9p9HoJsMDMLNcF3X0rYVp83H2nmT0CDE8YZ2VlW4kx9QR8ezs88ABMmVLtKEVEcorbZ/IGoSaR1DBgY9r+puhY1jLuvgt4DTg4OneEmf3OzO4zsw9mXtzM3gL8A/DLEsRaWZkrMb72Glx1FdxwA/zwh/Dgg9WOUEQkJ3PP9fhIWiGzC4CJwMfdfU/RNzNrAya5+znR/nRgnLvPSiuzLiqzKdrvAMYR+mWa3H2zmbUCtwNvd/fXo3L1wM+Be9z9u2RhZjOAGQAtLS2tixcvLupzdHZ20lTB0VWHrFjBiOuu49Vjj+WQFSuo27aN3YMG8cKHPsTG009n+7B983Gl4+suxZeM4ktG8SUzYcKENe4+dr8T7l5wA/4DeAb4I3AN8O2M7fKY13kv4cc+tf9PwD9llLkHeG/0uh54iSjpZZRbBYxN278e+H6cONyd1tZWL9bKlSuLfm9R7rrLva7OvV8/9zBzV9gaGtwbG92XLatufN2k+JJRfMkovmSAhz3Lb2rcPpM2YE/0435SlvMOfD3GdR4CRpnZEcCzwFTgzIwyS4GzgAei+65wdzezocDL7r7bzI4ERgGpvpd/BQ4Ezon5eXqOjg447bTQ9JUp1WHf1hb6XNRJLyJVEiuZuPsRpbiZu+8ys1mE2kcdcL27rzezeYRstxS4DrjRzNqBlwkJB+B4YJ6ZdRES20x3f9nMhgPfAP4APBL11S/w5IMFaoPm7hKRHiBuzaRk3H0ZsCzj2Ny019sJa85nvu824LYsxzcR5gfrnTR3l4j0APlmDT4Z+LW7vx69zitKElJqmrtLRHqAfDWTO9k7a/CdhH6RXDUAzRpcLpq7S0R6gHzPmRwBPJr2+sjob7btyDLG2LfFmburvh5OOQXOPReamzlh4kRobg77WlRLRCog36zBz2R7LRU2ezYsWpS/32TXLrj11jD1SldXqD6mlv1dtChM1zJ5cqUiFpE+qFuzBptZvZkdaWajM7dyBdjnpebuamzcv4bS0AADB4aayY4d+yccLfsrIhUSd9bgBjP7AfA64cHFx7JsUi6pubtmzAjNV/36hb8zZsCpp0LuqcuC1NBhEZEyiVszmUuYNfhsQif8LOBzhDmwnibMhyXllG3urgULYOnS+EOHRUTKJG4yOZ0wk+8t0f6D7n6Du38Y+DVhpl+pBg0dFpEaEDeZHAo85e67ge3AQWnnfgycWurAJKa4Q4ILlevoeHM02JvNaBoNJiIxxU0mzwNviV7/iTC1SYomhKqmUiz7u3w5jBkTRn9t2RKmkUyNBhszJpwXEckjbjJZBaTWD7kW+Ccz+4mZ/RC4ErijDLFJHHGW/a2vz73sb0dHGO21datGg4lI0eImk28ANwB4WCvka8DhwDuB/wT+sSzRSWGFhg43NMCQIfDKK9mbsS65JP5EkiIiORRMJmbWQGjKejl1zN3nu/v73f1Yd/+6u79RziClgIyhw262d+jwE0/AccfBuHHZm7F+/GONBhORxOLUTHYDK4C3lTkWSSJt6PB9K1bsHToMoc8jejp+H4WSSDqNBhORPAomEw/L9P4R+OvyhyMlF2c9lDgaGzXaS0Ry6k6fyVwz+/tyBiNlEGc9lEL69YPt2zXaS0RyyreeyfHAI+7eCVwMHAw8ambPAi8Qpp1/k7sfV85ApUilaJ7asydsmbRssIhE8q1nshJ4L2E9k3XRJj1N3PVQIIz8Sq/FNDTsTSLZ1qBP0bLBIn1evmTy5uyB7v65CsQi5TBtWmiOytfU1dAAn/oUHHhgGLXV2RmS0PTp8KMfwRsFButp2WCRPq9bU9BLDxTnocaGBrj00uwTSW7dGu8+W7aog16kD8tXMwE42cxiDQl29xtKEI+UWuqhxra2vX0cKamHGpcsyd3fEbeZzH3fGpAW5xLpUwolk7kxr+NET8gXYmaTgO8R1oxf6O7fyjg/ILpWK7AZ+JS7P21mI4AngCejor9195nRe1qBHwGDgGXA+e6+zwCBPi31UOP8+fs3Y114Yf6O8zjNZCnZnmNRB71In1ComWsCMDjG1hznZmZWB1wFTAZGA2dkWaXxbOAVdz8KmA9cnnauw92PibaZacd/AHwBGBVtk+LE06fkWg+l0A98nGayQjQdi0ivVyiZbHP3N+JsMe93HNDu7hvcfSewmP3XQpkCLIpeLwFONMu9lKCZvRVodvffRrWRG4CPx4xHCik091ccmo5FpNcr1MxVasOAjWn7m4Bxucq4+y4ze43wjAvAEWb2O8LywRe7+/1R+U0Z1xyW7eZmNgOYAdDS0sKqVauK+hCdnZ1Fv7cSSh7foEEMvOYaht96K399773UbdvG7kGD+N+TTmLYHXdQYNFgAHzLFu6LYupz31+JKb5kFF+ZuHvWDdgDHJfrfDEb0EboJ0ntTwcWZJRZBwxP2+8AhgADgIOjY62EhNMMjAX+b1r5DwJ3FoqltbXVi7Vy5cqi31sJFY1v8GD30P2ef2turk58RVB8ySi+ZGo9PuBhz/KbmrOZy937ufuDJc5dzxJWbUwZHh3LWsbM6oEDgc3uvsPdN0exrSEkmaOj8sMLXFPKpRSLc4lIj1fp50weAkaZ2RFm1h+YCizNKLMUOCt63QascHc3s6FRBz5mdiSho32Duz8PvG5m74n6Vj6DFuuqnLjPseRanEtEeoWKJhN33wXMAu4hDPO9xd3Xm9k8MzslKnYdcLCZtQNfAeZEx48H1prZo4SO+Znunlpj5VxgIdBOqLFo5sFKKdRBbxbWVdGwYJFerdId8Lj7MsKzIOnH5qa93g6cluV9twG35bjmw8A7ShupxJbvOZaPfSz8nTgxzC58002ckDo/bVqo2SjRiPR4FU8m0kulnmPJNj/X5z8PU6aEtei7usLoLz0hL9KraG4uKa+OjpBg3LM/Ib91a3hCXnN4ifRoSiZSXnFWeozzhHxHR3knkky7/gkTJ+5//XLfX6SHUzKR8oqz0mOhJ+SXLw8rOpZrpceM61vm9efNK+/9RXoBJRMpr7grPeYq19ERmsG2bs3fTLZiRXE1hzjXv+SSwvdXDUX6OCUTKa+mpmTl4jST7dgBH/lIcTWHONcvRBNZiiiZSJklfUI+TjPZ7t2wa1dxNYc41y9EE1mKKJlImcV5Qr6+Hj75yezNVHGbyfLJV3MoxfVLeR2RHkrJRMqr0BPy/fuHZPKxj2VvpirFGmf5ag5xm+EKKdV1RHooJRMpv9QT8jNmQHMzbhZqHjNmhP6MHTtg27bszVSlkqvmEKcZrhBNZCmiZCIVkrbS430rVuxd6XHJktLUPgrJVXOYPTv5/TWRpYiSiVRZdzrAszWT1dWFrdD7ctUcfvMbaGnJ3QzX2AiXXZb9fH00G9EVV2h+MenzlEykuuJ2XKdmH07voJ8xA37xCxgwoPB7s3XwT50KF1wAd9+duxlu7VqYO3ef82++/4tfDInkP/4DHnpIT8hLn6aJHqW6mppCZ3shgwfnnkhyyZIw/Lera99aTkNDqD3U1cHJJ8OePXvPb9kCN98cBgBs3Bj6daLr37dqFePHj9/3Hvkmsly9Gt7znnCf9OtrIkvpQ1QzkeoqxUqNGR38+9Rc7rwzPIOyY0f25rSdO5M9wd7RAXfdtW+iStET8tKHKJlIdZVqpca0Dn527963g3/37vzvTfIEe6kmsqw2TWQpCSmZSHUVeg6lsTGcL7aDuxQTTVbz+pVQ7ok0pU9QMpHqy9dMtXZtsv6GpBNNlup9W7bU5n/5x51Is9pxSs1TMpHakKuZKumQ26QTTZbqfe61+V/+vaWZTqpOyUR6t1J08Ce9fko5ptBPKm4z3aJFtVmzkppR8WRiZpPM7EkzazezOVnODzCzm6Pzq81sRMb5w8ys08wuSjt2oZmtN7N1ZvY/Zjaw/J9EeoRSdfAnuX4hSabQT6o7zYC1WLOSmlHRZGJmdcBVwGRgNHCGmY3OKHY28Iq7HwXMBy7POP8d4M3/95rZMOAfgbHu/g6gDphank8gPU65O/gLXT+OJFPoJ9Wd5j31qUgela6ZHAe0u/sGd98JLAamZJSZAiyKXi8BTjQzAzCzjwN/AtZnvKceGGRm9UAj8FyZ4peeqJwd/IWuH/6vm0w5+yxKMdGl+lQEMK/EJHupm5m1AZPc/Zxofzowzt1npZVZF4V99XcAAA+HSURBVJXZFO13AOOA7cC9wEnARUCnu18RlTkf+CawDfiFu386x/1nADMAWlpaWhcvXlzU5+js7KSphqccV3zJlDK+D3z0o9Rv3Zr4OrsaG/n1XXcBpY1v4LPPctxZZ9Gv0LM4BZQrvnJQfMlMmDBhjbuP3e+Eu1dsA9qAhWn704EFGWXWAcPT9juAIcAVwOnRsUuBi6LXBwErgKFAA3A7MK1QLK2trV6slStXFv3eSlB8yZQ0vi99yb2hwT30NBS/mYVrDR7se8zcBw8O++3t4T7t7W+e92znc/nhD92HDXNvbNw/zu7E3a9feb6/MlB8yQAPe5bf1Eo3cz0LHJq2Pzw6lrVM1Gx1ILCZUDv5tpk9DVwA/LOZzQI+BPzJ3f/i7l3AT4H3lfNDiMRWig562GdosWV2gM+bV/ihw2xPuLe1hfjuvTd3M90BB8SLr4b/S7okNENAQZWe6PEhYJSZHUFIGlOBMzPKLAXOAh4g1GRWRNnwg6kCZnYpoZlrgZmNA95jZo2EZq4TgYfL/UFEYkl10OeaiHLPnvA6TjNTtg7wri645JLc5bu64BOfCD+A6Z38W7bAbbeFGZeffnqfiS73sWdPSEr5hg/39sXBli/f/38/TeS5n4rWTNx9FzALuAd4ArjF3deb2TwzOyUqdh1wsJm1A18B9hs+nHHN1YSO+keAxwif6ZoyfQSR7svXQR9nCv2kcq1kmTqXbzRWuYdW1zrNEBBbxZ8zcfdl7n60u490929Gx+a6+9Lo9XZ3P83dj3L349x9Q5ZrXOpR53u0f4m7v83d3+Hu0919R+U+kUgMuZ7wnzgx+dDipPKNxso39Lm+PoxWu+CCwkOrq91MlHb/EyZOjH//3jJDQCW+/2wdKX1hUwd89Si+LNrb3c87z725OXRmNzeHfbPknfdxtubm4uK7/Xb3IUPcf/az3AMEli3L3cHf2BjOx/l+8g0wyHc+zv1zvf+AA0rz/XVDyf//V4rvPw05OuCr/qNerU3JpHoUXzcMHlyZZJI2GqvbLr44/ADX1+//YzVwoPuAAfnv3diYf9RZoR/Dyy7LfT7O/QcMcB80qGSj2ZIq6f//2tvDd5Pk+8+QK5lobi6RWlaKhwrjKHY0VkcHfOc74Wdp1659z3V1wfbtoV8mn3zNRHH6LC65JPf5OPfP1adUqHkrXdLRbMU2wxVSwWY6JRORWlaqocX5JBmNFefHqpB8672U4vrllnQ0W8Z6MvsN/U4y91kF19tRMhGpZXHmFrvsstznBw4sPFosyWisOD9WceSacLJU1y+n+vriv79yjxYr93o+aZRMRGpdxtBiN9t3brG5c3MPPV63Dn72s/JNdFmCHyEgdzNRqa5fCtm+v4YGGD48NJMVM1oqbjPUpZcWd/1yr+eTLltHSl/Y1AFfPYovmaLiyzUaqxsdr1mVYoBAfb37tGnJRlOVe2tqyv79/fGP7hMmuNfVFTdaqjvfXzHXjzOdT0ND+CwxoQ54kT6sXCtZlmKAwK5dcOut2aeD2b492bVLoaEBzjor+/dnBqtXh2PFNFN1p+ZVzPUr+NCpkomIFC/Oj9WAATBoUO4+nYaGMKIq249lwtmMY90/SZ9S0tFSpWheKvTQ6dVXh9f1GbNnlaKZM42SiYgUL84AgZ/9DB57LHufzqmnFr5HXV34ISxmAEKW++/T55S0TynpaKlSrSeTbzTW7bfDl78MX/xiedbzScnW9tUXNvWZVI/iS6Ym40vrk9ljFr9PJm6fQa4+i/Qn4GP2CWX9/ortU4o7Q0Guhxrb20uzREGu699xh/vRR7tv25b/c3QDOfpMKj1rsIj0Rqk+mQULuG/VKsaPHx/vfXH7DLZuzT6rcZb7F6XY9zc1hf6dQhobw+irm24Kn7mpKdRK3vnOUEvYunX/pZsbGuIPi87WXLZlC8yaFWY2Hjgw3nUSUDOXiFRPJYeulkOcZqp+/cJAgswBBtdeCzNnwsUX526G+/SnC1+/vh5OOWX/ocMf+ACMHQsTJpTu8+b7mBW5i4hINnF+jGt5vZQ4AxD27Nm/1gF7p5/5xjfC32i02H0rVuwdLXbZZYWvv2sX3HLL/slq7Vq4++5kT9B3g5KJiFRPT18vpdAAhLq6UFPIp9glANJHw+3cmb1JbNu2iq23omQiItUTZzRYiYaulk2+xc8GDty7mmYuhUZj5bt+nNFwFVpvRclERKor349lKYeullOuh0K3bo33/kIDEXJdf+nSik3kWIhGc4lI9SUdjVWr4o72KnaAQQUncixENRMRkXIp9wCDGhoNp2QiIlIu5R5gUEOj4SqeTMxskpk9aWbtZjYny/kBZnZzdH61mY3IOH+YmXWa2UVpx95iZkvM7A9m9oSZvbf8n0REpIByDzCoodFwFU0mZlYHXAVMBkYDZ5jZ6IxiZwOvuPtRwHzg8ozz3wEyB05/D7jb3d8GvBN4otSxi4gUpZwDDGpoNFylaybHAe3uvsHddwKLgSkZZaYAi6LXS4ATzcwAzOzjwJ+A9anCZnYgcDxwHYC773T3V8v6KUREuqNcSwBAzYyGszBvV2WYWRswyd3PifanA+PcfVZamXVRmU3RfgcwDtgO3AucBFwEdLr7FWZ2DHAN8DihVrIGON/d38hy/xnADICWlpbWxYsXF/U5Ojs7aarV6R1QfEkpvmQUXzK1Ht+ECRPWuPvYzOM9aWjwpcB8d++MKiop9cCxwJfdfbWZfQ+YA/yfzAu4+zWExMPYsWM99mR0GVZ1ZyK7KlB8ySi+ZBRfMrUeXy6VTibPAoem7Q+PjmUrs8nM6oEDgc2E2kmbmX0beAuwx8y2E5rCNrn76uj9SwjJREREKqTSyeQhYJSZHUFIGlOBMzPKLAXOAh4A2oAV0Rz6H0wVMLNLCc1cC6L9jWb2t+7+JHAioclLREQqpKLJxN13mdks4B6gDrje3deb2TzCgitLCR3pN5pZO/AyIeEU8mXgx2bWH9gAfK7QG9asWfOSmT1T5EcZArxU5HsrQfElo/iSUXzJ1Hp8h2c7WNEO+N7CzB7O1gFVKxRfMoovGcWXTK3Hl4uegBcRkcSUTEREJDElk+JcU+0AClB8ySi+ZBRfMrUeX1bqMxERkcRUMxERkcSUTEREJDElk24oNH1+LTCzp83sMTN71MweroF4rjezF6M511LH/srM7jWzP0Z/D6qx+C41s2ej7/BRMzu5ivEdamYrzexxM1tvZudHx2viO8wTX018h2Y20MweNLPfR/FdFh0/Ilrioj1a8qJ/jcX3IzP7U9r3d0w14usO9ZnEFE2f/xRhoslNhKf5z3D3mnra3syeBsa6e0089GRmxwOdwA3u/o7o2LeBl939W1FSPsjdv15D8V1KNJFoNWJKZ2ZvBd7q7o+Y2WDCRKYfBz5LDXyHeeI7nRr4DqMZxw+I5vRrAH4NnA98Bfipuy82s6uB37v7D2oovpnAne6+pNIxFUs1k/jiTJ8vGdz9V4SZDNKlLzOwiPDjUxU54qsZ7v68uz8Svd5CWKtnGDXyHeaJryZ4kFoAvSHaHJhImMcPqvv95Yqvx1EyiW8YsDFtfxM19I8mjQO/MLM10ZT7tajF3Z+PXv8v0FLNYHKYZWZro2awqjXDpbOw6ui7gNXU4HeYER/UyHdoZnVm9ijwImEZiw7gVXffFRWp6r/lzPjSJq39ZvT9zTezAdWKLy4lk97nA+5+LGE1y/OiZpyaFU3iWWv/JfYDYCRwDPA8cGV1wwEzawJuAy5w99fTz9XCd5glvpr5Dt19t7sfQ5il/DjgbdWKJZvM+MzsHcA/EeJ8N/BXQFWagbtDySS+ONPnV527Pxv9fRH4GeEfT615IWprT7W5v1jlePbh7i9E/8D3ANdS5e8waku/Dfixu/80Olwz32G2+GrtO4xiehVYCbwXeIuFJS6gRv4tp8U3KWo+dHffAfyQGvj+ClEyie/N6fOjkR9TCdPl1wwzOyDqBMXMDgA+DKzL/66qSC0zQPT3jirGsp/Uj3TkE1TxO4w6aK8DnnD376SdqonvMFd8tfIdmtlQM3tL9HoQYQDNE4Qf7baoWDW/v2zx/SHtPxSM0J9Ti/+O96HRXN0QDW/8Lnunz/9mlUPah5kdSaiNQFhe4CfVjtHM/gcYT5hW+wXgEuB24BbgMOAZ4HR3r0oneI74xhOaZxx4GvhiWv9EpeP7AHA/8BiwJzr8z4R+iap/h3niO4Ma+A7NbAyhg72O8B/Pt7j7vOjfymJCE9LvgGlRLaBW4lsBDAUMeBSYmdZRX5OUTEREJDE1c4mISGJKJiIikpiSiYiIJKZkIiIiiSmZiIhIYkomIr2EmY03M4+eoBapKCUTERFJTMlEREQSUzIRScjMPmhm95nZVjPbbGbXpk1r89mo6endZna/mW0zs6fM7BNZrjPLwmJXO6JFmy7MUmaMmf3czF41s85oYaWTMooNMbNbo/MbzOzcMn10kTcpmYgkYGbvB/4vYRr4NuAC4GTC5HzpbibM//RJwtQjt5rZO9Ou8wXgPwlzbv0DcCtwpaWt6GlmbwN+A7yVsHjSJwjT56RPQAphYsXfR+dXAVeZWc1PFCg9m6ZTEUnAzO4Hdrn7hLRjE4FfAn8PjCUklm+4+79F5/sBjwOPuvvUaH8j8At3/1zadf4L+DRh7ZLt0TxiHwRGufu2LLGMJ0xg+C/uPjc61gA8B1zn7jW51LT0DqqZiBTJzBoJ05nfYmb1qY2w9GoX0JpWPDUBJ9G07Hewd1rx4cDfEGoj6W4GmglJCcLqgDdnSyQZfpF2ry7gj9E9RMpGyUSkeAcRZnv9L0LySG07CMuvpjc/Za438iKhuYq0vy9klEnt/1X092DCQlOFvJqxvxMYGON9IkWrL1xERHJ4lTDF+qXAsiznnyOsKQNwCLA57dwh7E0Mz6cdS5daijc1tfxm9iYekZqimolIkdz9DeC3wN+6+8NZtufSir85eivqI5kCPBgd2kRIPKdl3OJ04HVChz2EfpjTzUy1DKk5qpmIJPM14JdmtgdYAmwhLFj1UeAbaeXOMbOdhBXzzgGOIiwghbvvMbNLgf82s83AvcAJwJeAf3b37dE1LiOs+PkrM7uSUFN5F7DZ3a8v66cUKUA1E5EE3P3XwPGEVfFuBH5OSDAb2bcPZCqhdnI78E7gU+7+u7TrXAucH5W5k5BoZrv7t9LKPAl8AHgJWEjo1G8jrLQoUlUaGixSRmb2WcLQ4MG1vuyqSBKqmYiISGJKJiIikpiauUREJDHVTEREJDElExERSUzJREREElMyERGRxJRMREQksf8PbszVrrQ5bb4AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["[0.8141352695519053, 39.28888888888889, 4.364444444444445, 4.038518518518519]"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"e7bjoIMsKg-o","executionInfo":{"status":"ok","timestamp":1595668639804,"user_tz":-120,"elapsed":148915,"user":{"displayName":"Sergey Vilov","photoUrl":"","userId":"16545205334574304565"}},"outputId":"8e499fae-53ab-49e0-f85f-67966f3bf3e7","colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["ab715b5659f34c14be792007cd9ce260","ea8c657fe64b4d17a160b321b3398012","a5b9e221154a47c1b2b4fb6f839d5eed","a539926dad694b0d8a4f4a80c3edc6bc","d1d513e8344c4cf683fa740f6673faf2","1d94bcf6576e4a46904a818a17e13ebe","be6f82b4bd5847f284b3ab139c271f11","ab4385607b0b4802bf6a7042601f9248"]}},"source":["# max_itr_valid_metric = math.ceil(len(valid_dataset)/float(valid_data_loader.batch_size))\n","# val_metric, TP_val, FP_val, FN_val = validate(model, valid_data_loader, max_itr_valid_metric, detection_thr = 0.15)\n","# print(FP_val)\n","# print(FN_val)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab715b5659f34c14be792007cd9ce260","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=85.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n","  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"],"name":"stderr"},{"output_type":"stream","text":["2.242962962962963\n","5.579259259259259\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2qi67CGG54T_"},"source":["import pickle\n","import copy\n","from datetime import datetime\n","import time\n","import os\n","\n","base_models_dir = '/content/drive/My Drive/DL/wheat_detection/models/SGD_NMS083_AUGM2x_1024_FOLD_' + str(validation_fold) + '/'\n","if not os.path.exists(base_models_dir):\n","   os.mkdir(base_models_dir)\n","\n","num_epochs = 44\n","\n","if load_weights==False:\n","  best_val_metric = 0.0\n","  hist = {'train_loss':[], 'val_metric':[], 'train_metric':[]}\n","  first_epoch = 0\n","\n","# first_epoch = 24\n","\n","# max_itr_train_metric = math.ceil(len(valid_dataset)/float(train_data_loader.batch_size))\n","max_itr_valid_metric = math.ceil(len(valid_dataset)/float(valid_data_loader.batch_size))\n","\n","for epoch in range(first_epoch, num_epochs+1):\n","\n","    # if epoch <=8:\n","    #     train_dataset.augment = False\n","    #     train_dataset.augment_colorspace = False\n","    # else:\n","    #     train_dataset.augment = True\n","    #     train_dataset.augment_colorspace = True\n","\n","    since = time.time()\n","    print(f\"Training for epoch: {epoch}\")\n","    train_loss = train(model)\n","    training_time = time.time() - since\n","    print('complete in {:.0f}m {:.0f}s'.format(\n","        training_time // 60, training_time % 60))\n","\n","  #   print(f\"EPOCH #{epoch}\\n loss_box_reg: {train_loss[0]}\\n loss_classifier: {train_loss[1]}\\n\\\n","  #  loss_objectness: {train_loss[2]}\\n loss_rpn_box_reg: {train_loss[3]}\\nTOTAL LOSS: {train_loss[4]}\\n\")\n","    print(f\"EPOCH #{epoch}\\n TOTAL LOSS: {train_loss}\\n\")\n","\n","    since = time.time()\n","    print(f\"Computing training metric\")\n","    # train_metric, TP_train, FP_train, FN_train = validate(model, train_data_loader, max_itr_train_metric)\n","    train_metric, TP_train, FP_train, FN_train = np.nan, np.nan, np.nan, np.nan\n","    training_metric_time = time.time() - since\n","    print('complete in {:.0f}m {:.0f}s'.format(\n","        training_metric_time // 60, training_metric_time % 60))\n","\n","    since = time.time()\n","    print(f\"Computing validation metric\")\n","    val_metric, TP_val, FP_val, FN_val = validate(model, valid_data_loader, max_itr_valid_metric)\n","    # val_metric, TP_val, FP_val, FN_val = np.nan, np.nan, np.nan, np.nan\n","    validation_metric_time = time.time() - since\n","    print('complete in {:.0f}m {:.0f}s'.format(\n","        validation_metric_time // 60, validation_metric_time % 60))\n","\n","    hist['train_loss'].append(train_loss)\n","    hist['val_metric'].append([val_metric, TP_val, FP_val, FN_val])\n","    hist['train_metric'].append([train_metric, TP_train, FP_train, FN_train])\n","\n","    time.sleep(2)\n","\n","    disp_progress(hist, epoch)\n","  \n","  #   print(f\"EPOCH #{epoch}\\n loss_box_reg: {train_loss[0]}\\n loss_classifier: {train_loss[1]}\\n\\\n","  #  loss_objectness: {train_loss[2]}\\n loss_rpn_box_reg: {train_loss[3]}\\nTOTAL LOSS: {train_loss[4]}\\n\")\n","    print(f\"EPOCH #{epoch}\\n TOTAL LOSS: {train_loss}\\n\")\n","    print(f\"TRAIN METRIC:{train_metric} TP:{np.round(TP_train)} FP:{np.round(FP_train)} FN:{np.round(FN_train)}\")  \n","    print(f\"VALIDATION METRIC:{val_metric} TP:{np.round(TP_val)} FP:{np.round(FP_val)} FN:{np.round(FN_val)}\\n\")   \n","      \n","    if epoch%2==0:\n","    # if val_metric > best_val_metric or epoch==num_epochs-1:\n","\n","        # print(f'BEST EVALUATION METRIC! OLD:{best_val_metric} NEW:{val_metric}')\n","        print(f'SAVING MODEL STATE\\n')\n","\n","        if val_metric > best_val_metric:\n","          best_val_metric = val_metric\n","\n","        now = datetime.now()\n","        # file_name = base_models_dir + now.strftime(\"%d_%m\")\n","\n","        file_name = base_models_dir + now.strftime(\"%d_%m\") + '_epoch_' + str(epoch)\n","\n","        torch.save(model.state_dict(), file_name+\"_weights\")\n","\n","        # torch.save(optimizer.state_dict(), file_name+\"_optimizer\")\n","\n","        # date_time = now.strftime(\"%d_%m_%y_%H_%M_%S\")\n"," \n","        model_meta = {'hist': hist,\n","                      'epoch': epoch,\n","                      'lr_scheduler': lr_scheduler}\n","\n","        pickle.dump(model_meta, open(file_name+\"_hist\", 'wb'))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dg8X2q7rG_A"},"source":["epoch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YLG_4p9UrH9d"},"source":["stop"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Uu3KknOe-Uf"},"source":["hist['val_metric'].append([val_metric, TP, FP, FN])\n","hist['train_metric'].append([train_metric, TP_train, FP_train, FN_train])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t9A9YP44rbNv"},"source":["10%2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2QGe_zKuaZVh"},"source":["  images, targets, _ = next(iter( train_data_loader))\n","       \n","  images = list(image.to(device)for image in images)\n","  targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","  loss_dict = model(images, targets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEh9zMF9RMXY"},"source":["valid_iterator = iter(valid_data_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5eZ4rzfe5uGF"},"source":["images, targets, _ = next(valid_iterator)\n","\n","model.eval()\n","\n","outputs = model(list(image.to(device) for image in images))\n","\n","idx_image = 5\n","\n","pred_boxes =  outputs[idx_image]['boxes'].cpu().tolist()\n","conf = outputs[idx_image]['scores'].cpu().tolist()\n","gt_boxes = targets[idx_image]['boxes'].tolist()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"juN6XXGdLhda"},"source":["sample = images[idx_image].permute(1,2,0).cpu().numpy()\n","\n","sample = sample.astype(np.float32) #btw 0 and 1\n","\n","fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","\n","for box in pred_boxes:\n","    cv2.rectangle(sample,\n","                  (int(box[0]), int(box[1])),\n","                  (int(box[2]), int(box[3])),\n","                  (1, 0, 0), 3)\n","\n","for box in gt_boxes:\n","    cv2.rectangle(sample,\n","                  (int(box[0]), int(box[1])),\n","                  (int(box[2]), int(box[3])),\n","                  (0, 1, 0), 3)   \n","ax.set_axis_off()\n","ax.imshow(sample)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ecYENYbRPM3i"},"source":["conf = outputs[idx_image]['scores'].cpu().tolist()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_Od0MTHO-Jg"},"source":["get_metric_image(gt_boxes, pred_boxes, conf, 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vPcoCLhkMtXC"},"source":["# model.eval()\n","\n","tdl = iter(train_data_loader)\n","\n","# max_itr = 50\n","metric = []\n","# for itr in range(max_itr):\n","\n","for images, targets, _ in tdl:\n","       \n","  images = list(image.to(device)for image in images)\n","  targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","# outputs = model(list(image.to(device) for image in images))\n","\n","  for idx_image in range(len(images)):\n","\n","\n","# pred_boxes =  outputs[idx_image]['boxes'].cpu().tolist()\n","# conf = outputs[idx_image]['scores'].cpu().tolist()\n","    gt_boxes = targets[idx_image]['boxes'].tolist()\n","    pred_boxes = gt_boxes\n","    conf = np.ones((len(pred_boxes),1))\n","\n","\n","    metric.append(get_metric_image(gt_boxes, pred_boxes, conf, 0.5))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QaVvyfPIaeLK"},"source":["((len(train_df['image_id'].unique())-49)+len(valid_df['image_id'].unique()))*0.2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rvSGDex1dmNO"},"source":["validate(model, train_data_loader, 42, 0.75)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rV4nAE_5hiSf"},"source":["next(a)"],"execution_count":null,"outputs":[]}]}